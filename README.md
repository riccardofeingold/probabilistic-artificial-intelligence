# Probabilistic Artificial Intelligence 2023
## Task 0: Implementation of Baysian Interference
The goal of this simple exercise is to calculate the posterior probabilities of $P(H_i|X)$ for $i=1,2,3$ using Bayes theorem. According this formula, the probability of the hypothesis $H_i$ given $X$ can be calculated by multiplying the sum of the porbability of all $X$ given $H_i$ with the corresponding prior probability for the hypothetis $H_i$. All this is divided by the marginal likelihood.

## Task 1: Gaussian Process Regression
The goal of this task was to model air pollution measurements using Gaussian Process Regression and predict the pollution at new locations. To implement the Gaussian process regressor I used the Sklearn library. Since the priors have zero mean, I enabled the option to normalize the target values, which gets reverted before the GP prediction happens. In order to find a suitable kernel function I implemented a 3-fold cross validator that tested 5 different kernels. For each model, the asymmetric cost gets calculated. Based on the results of the cross-validation, the superposition of the Matern kernel with nu=1.5 and length_scale=0.054 and the white kernel with noise_level=0.00528 received the lowest average cost over all folds. The white kernel has been added due to the fact that the training data contains noise. I also tested one kernel without a white kernel for comparison. Other kernels I tested can be found inside the model_selection method and the corresponding results are mentioned as comments in the main method. To ensure that the predictions at areas with binary value 1 are not below the ground truth, I decided to set the predictions equal to the sum of the posterior standard deviation and the posterior mean for these areas. To manage the large dataset problem, I used the train_test_split method from Sklearn to randomly sample 70% of the data as the training set. This ensures a manageable computational load without compromising the richness of the data.